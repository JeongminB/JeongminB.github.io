<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Per-Gaussian Embedding based Deformation for Deformable 3D Gaussian Splatting">
  <meta name="keywords" content="Per-Gaussian Embedding based Deformation for Deformable 3D Gaussian Splatting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Per-Gaussian Embedding based Deformation <br> for Deformable 3D Gaussian Splatting</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./css/bulma-slider.min.css">
  <link rel="stylesheet" href="./css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./css/index.css">
  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./js/fontawesome.all.min.js"></script>
  <script src="./js/bulma-carousel.min.js"></script>
  <script src="./js/bulma-slider.min.js"></script>
  <script src="./js/index.js"></script>
</head>
<body>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-2 publication-title">Per-Gaussian Embedding based Deformation <br> for Deformable 3D Gaussian Splatting</h2>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Jeongmin Bae<sup>1</sup>*,
            <span class="author-block">
              Seoha Kim<sup>1</sup>*,
            <span class="author-block">
              Youngsik Yun<sup>1</sup>,
            <span class="author-block">
              Hahyun Lee<sup>2</sup>,
            <span class="author-block">
              Gun Bang<sup>2</sup>,
            <span class="author-block">
              Youngjung Uh<sup>1</sup>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <sup>1</sup> Yonsei University, 
              <sup>2</sup> ETRI</span>
          </div>
          <h1 class="title is-4 publication-title">arXiv</h1>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a target="_blank" href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a target="_blank" href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a target="_blank" href="https://github.com/JeongminB/E-D3DGS"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

            
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
    <div class="is-centered has-text-centered">

      <video poster="" autoplay controls muted loop playsinline height="100%">
        <source src=".\videos\teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-justified">
        Existing field-based deformable 3D Gaussian Splatting methods predict Gaussian deformations at similar locations to be entangled. 
        As a result, dynamic Gaussians influence adjacent static Gaussians, causing static regions to move along the nearby dynamic regions and exhibit degraded quality (<em>left</em>). 
        Our model solves the problem by employing <b>per-Gaussian latent embeddings</b> to predict deformation and achieves a clearer representation of dynamic motion (<em>right</em>).
      </h2>
      </div>
  </div>
</div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
    <div class="container has-text-centered">
      <h2 class="title is-2" style="margin-top: 60px;">Abstract</h2>
      <h2 class="subtitle has-text-justified">
        As 3D Gaussian Splatting (3DGS) provides fast and high-quality novel view synthesis, it is a natural extension to deform a canonical 3DGS to multiple frames. 
        However, previous works fail to accurately reconstruct dynamic scenes, especially 1) static parts moving along nearby dynamic parts, and 2) some dynamic areas are blurry. 
        We attribute the failure to the wrong design of the deformation field, which is built as a coordinate-based function. 
        This approach is problematic because 3DGS is a mixture of multiple fields centered at the Gaussians, not just a single coordinate-based framework. 
        To resolve this problem, we define the deformation as a function of per-Gaussian embeddings and temporal embeddings. 
        Moreover, we decompose deformations as coarse and fine deformations to model slow and fast movements, respectively. 
        Also, we introduce an efficient training strategy for faster convergence and higher quality. 
        <br>
        <br>
      </h2>
    </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
    <div class="container has-text-centered">
      <h2 class="title is-2" style="margin-top: 60px;">Rendering Videos</h2>
      <h2 class="subtitle has-text-justified">
        We show the rendering results on three datasets: Neural 3D Video Dataset, Technicolor Light Field Dataset, and HyperNeRF dataset. 
        Our approach achieves high-quality rendering while effectively modeling complex dynamic changes.
        <br>
        <br>
      </h2>
      <h2 class="title is-4" style="margin-bottom: 5px;">Results on Neural 3D Video Dataset</h2>
      <div id="results-carousel" class="carousel results-carousel">
        
        <div class="item item-set1">
          <div class="columns vertical_center">
            <div class="column is-one-seconds">
              <div class="column">
                <figure>
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src=".\videos\1_sear.mp4"
                            type="video/mp4">
                  </video>
                </figure>
              </div>
            </div>
          </div>
        </div>
        
        <div class="item item-set2">
          <div class="columns vertical_center">
            <div class="column is-one-thirds">
              <div class="column">
                <figure>
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src=".\videos\2_steak.mp4"
                            type="video/mp4">
                  </video>
                </figure>
              </div>
            </div>
          </div>
        </div>
        
        <div class="item item-set3">
          <div class="columns vertical_center">
            <div class="column is-one-thirds">
              <div class="column">
                <figure>
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src=".\videos\3_martini.mp4"
                            type="video/mp4">
                  </video>
                </figure>
              </div>
            </div>
          </div>
        </div>
        
      </div>
  </div>
</div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
    <div class="container has-text-centered">

      <h2 class="title is-4" style="margin-top: 30px;">Results on Technicolor Light Field Dataset</h2>
      <div id="results-carousel" class="carousel results-carousel">
        
        <div class="item item-set1">
          <div class="columns vertical_center">
            <div class="column is-one-seconds">
              <div class="column">
                <figure>
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src=".\videos\birthday.mp4"
                            type="video/mp4">
                  </video>
                </figure>
              </div>
            </div>
          </div>
        </div>
        
        <div class="item item-set2">
          <div class="columns vertical_center">
            <div class="column is-one-thirds">
              <div class="column">
                <figure>
                  <video poster="" autoplay controls muted loop playsinline height="100%">
                    <source src=".\videos\train.mp4"
                            type="video/mp4">
                  </video>
                </figure>
              </div>
            </div>
          </div>
        </div>

        
      </div>
    </div>
  </div>
</div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
    <div class="is-centered has-text-centered">
      <!-- Comparison. -->
      <h2 class="title is-4" style="margin-top: 30px;">Results on HyperNeRF Dataset</h2>

        <video poster="" autoplay controls muted loop playsinline width="100%">
          <source src=".\videos\hypernerf_ours_compressed.mp4"
                  type="video/mp4">
        </video>
      </div>
  </div>
</div>
</section>

<section class="hero is-small">
  <div class="hero-body">
  <div class="container is-max-desktop">
  <div class="is-centered has-text-centered">
      <!-- Comparison. -->
      <h2 class="title is-2" style="margin-top: 60px;">Analysis</h2>
        <h2 class="title is-4">Deformation components</h2>
        <video poster="" autoplay controls muted loop playsinline width="100%">
          <source src=".\videos\deformation.mp4"
                  type="video/mp4">
        </video>
        <h2 class="subtitle has-text-justified">
          <p>Our corse-fine deformation consists of two decoders, each in charge of coarse and fine deformation. 
            The video above is the result of rendering each deformation removed from the trained model. <br>
            <b>(a)</b> When both deformations are removed, rendering yields an image in canonical space. <br>
            <b>(b)</b> Coarse deformation handles large or slow changes, producing results similar to the full rendering. <br>
            <b>(c)</b> Fine deformation handles fast or detailed changes, yielding rendering similar to canonical space. <br>
            <b>(d)</b> Full rendering results come from applying both coarse and fine deformations to the canonical space.
          </p>
        </h2>

        <h2 class="title is-4" style="margin-top: 30px;">Visualization of the magnitude of deformation</h2>
        <video poster="" autoplay controls muted loop playsinline width="70%">
          <source src=".\videos\magnitude.mp4"
                  type="video/mp4">
        </video>
        <h2 class="subtitle has-text-justified">
          <p>We visualize the magnitude of position changes in the deformation of Gaussian parameters.
            <b>Coarse deformation</b> (<em>blue</em>) captures <b>large and slow changes</b>, such as the movement of
            the head and torso, while <b>fine deformation</b> (<em>red</em>) is responsible for <b>fast and detailed
            changes</b> of arms, tongs, shadows, <em>etc</em>. 
            <!-- By downscaling and sampling the temporal embedding grid for coarse decoder, 
            our model can effectively separate and model slow and fast deformations in the scene. 
            Please see the main paper for the details of our method. -->
          </p>
        </h2>
      </div>
  </div>
</div>
</section>

</body>
</html>